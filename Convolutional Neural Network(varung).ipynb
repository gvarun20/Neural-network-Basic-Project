{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 3\n",
    "data_augmentation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the image (SHAPE x SHAPE)\n",
    "shapex, shapey = 28, 28\n",
    "# number of convolutional filters to use at each layer\n",
    "nb_filters = [32, 64]\n",
    "# level of pooling to perform at each layer (POOL x POOL)\n",
    "nb_pool = [2, 2]\n",
    "# level of convolution to perform at each layer (CONV x CONV)\n",
    "nb_conv = [3, 3]\n",
    "# the MNIST images are greyscale\n",
    "image_dimensions = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('mnist_train .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcol = train.columns[1:]\n",
    "ycol = 'label'\n",
    "features = train[Xcol].values\n",
    "labels = train[ycol].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29400, 784)\n",
      "29400 train samples\n",
      "12600 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between tran and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn 1D feature vector into 3D cube\n",
    "def makeImage(vectors):\n",
    "    images = []\n",
    "    nsamples = len(vectors[:, 0])\n",
    "    for ivector in range(nsamples):\n",
    "        vector = vectors[ivector, :]\n",
    "        npixels = len(vector)\n",
    "        nx = int(np.sqrt(npixels))\n",
    "        ny = int(np.sqrt(npixels))\n",
    "        image = np.zeros((nx, ny))\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                image[j, i] = vector[j * nx + i]\n",
    "        images.append(image)\n",
    "    images = np.array(images)\n",
    "    images = np.reshape(images, (nsamples, 1, nx, ny))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = makeImage(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = makeImage(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29400, 1, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29400,), (29400, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 64)        36928     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 11, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7744)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               3965440   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,026,314\n",
      "Trainable params: 4,026,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "nb_filters = [32, 64]\n",
    "nb_conv = [3, 3]\n",
    "nb_pool = [2, 2]\n",
    "shapex, shapey = 28, 28  # replace with the actual dimensions of your input images\n",
    "nb_classes = 10  # replace with the actual number of classes\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Input Layer\n",
    "model.add(Conv2D(nb_filters[0], kernel_size=(nb_conv[0], nb_conv[0]), padding='valid', input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Hidden Layer 1\n",
    "model.add(Conv2D(nb_filters[1], kernel_size=(nb_conv[1], nb_conv[1]), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Hidden Layer 2\n",
    "model.add(Conv2D(nb_filters[1], kernel_size=(nb_conv[1], nb_conv[1])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool[1], nb_pool[1])))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully Connected Layers\n",
    "# Fully Connected Layers\n",
    "# Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=nb_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Convolution2D(nb_filters[1], nb_filters[0], nb_conv[0], nb_conv[0], border_mode='full'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Convolution2D(nb_filters[1], nb_filters[1], nb_conv[1], nb_conv[1]))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(poolsize=(nb_pool[1], nb_pool[1])))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(nb_filters[-1] * (shapex / nb_pool[0] / nb_pool[1]) * (shapey / nb_pool[0] / nb_pool[1]), 512))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(512, nb_classes))\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the image dimensions are the original dimensions divided by any pooling\n",
    "# each pixel has a number of filters, determined by the last Convolution2D layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SGD optimizer with momentum\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Compile the model using SGD optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation or normalization\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 1, 28, 28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m X_train_image \u001b[38;5;241m=\u001b[39m X_train_image\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m      9\u001b[0m X_test_image \u001b[38;5;241m=\u001b[39m X_test_image\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_image, Y_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0rckvsaq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Hi\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import generic_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "if not data_augmentation:\n",
    "    print(\"Not using data augmentation or normalization\")\n",
    "\n",
    "    X_train_image = X_train_image.astype(\"float32\") / 255\n",
    "    X_test_image = X_test_image.astype(\"float32\") / 255\n",
    "\n",
    "    model.fit(X_train_image, Y_train, batch_size=batch_size, epochs=10, verbose=1)\n",
    "    score = model.evaluate(X_test_image, Y_test, batch_size=batch_size, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "else:\n",
    "    print(\"Using real-time data augmentation\")\n",
    "\n",
    "    # Define data augmentation parameters\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=True,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False\n",
    "    )\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Transpose dimensions to match model's expected input shape\n",
    "    X_train_image = tf.transpose(X_train_image, perm=[0, 2, 3, 1])\n",
    "    X_test_image = tf.transpose(X_test_image, perm=[0, 2, 3, 1])\n",
    "\n",
    "    for epoch in range(10):\n",
    "        print('-'*40)\n",
    "        print('Epoch', epoch)\n",
    "        print('-'*40)\n",
    "        print(\"Training...\")\n",
    "        \n",
    "        # Batch train with real-time data augmentation\n",
    "        progbar = generic_utils.Progbar(X_train.shape[0])\n",
    "        \n",
    "        for X_batch, Y_batch in datagen.flow(X_train_image, Y_train, batch_size=batch_size):\n",
    "            loss = model.train_on_batch(X_batch, Y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"train loss\", loss)])\n",
    "\n",
    "        print(\"Testing...\")\n",
    "        \n",
    "        # Test time!\n",
    "        progbar = generic_utils.Progbar(X_test.shape[0])\n",
    "        \n",
    "        for X_batch, Y_batch in datagen.flow(X_test_image, Y_test, batch_size=batch_size):\n",
    "            score = model.test_on_batch(X_batch, Y_batch)\n",
    "            progbar.add(X_batch.shape[0], values=[(\"test loss\", score)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = makeImage(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredict = model.predict(test_image, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpredict = pd.DataFrame(np.argmax(ypredict, axis=1))\n",
    "dfpredict.columns = ['Label']\n",
    "dfpredict['ImageId'] = np.arange(28000) + 1\n",
    "dfpredict.to_csv('../Data/predict_CNNbenchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(ypredict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
