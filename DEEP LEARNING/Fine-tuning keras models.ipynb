{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate.We'll want to look at the results remembering that a low value for the loss function is good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "data=pd.read_csv('titanic_all_numeric.csv')\n",
    "predictors=data.drop(['survived'],axis=1).as_matrix()\n",
    "n_cols = predictors.shape[1]\n",
    "target =to_categorical(data.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_model():\n",
    "    model = Sequential()\n",
    "    # Add the first layer\n",
    "    model.add(Dense(32,activation='relu',input_shape=(n_cols,)))\n",
    "    # Add the output layer\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 3s 4ms/step - loss: 3.9261 - acc: 0.6162\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 1s 1ms/step - loss: 2.7504 - acc: 0.5892\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 1s 1ms/step - loss: 9.6159 - acc: 0.3895\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test =list([0.000001,0.01,1])\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model =get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer =SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors,target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model accuracy on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/1\n",
      "623/623 [==============================] - 2s 3ms/step - loss: 1.1762 - acc: 0.5907 - val_loss: 0.5920 - val_acc: 0.7015\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist =model.fit(predictors,target,validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping: Optimizing the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to monitor your model performance throughout optimization, we can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, we can also set a high value for epochs in your call to .fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 3s 5ms/step - loss: 1.1678 - acc: 0.5618 - val_loss: 0.6299 - val_acc: 0.6679\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 322us/step - loss: 0.7533 - acc: 0.5762 - val_loss: 0.5862 - val_acc: 0.6940\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 322us/step - loss: 0.6593 - acc: 0.6661 - val_loss: 0.5825 - val_acc: 0.7090\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 366us/step - loss: 0.6104 - acc: 0.6726 - val_loss: 0.5546 - val_acc: 0.7127\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 424us/step - loss: 0.6685 - acc: 0.6677 - val_loss: 0.7912 - val_acc: 0.6455\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s 347us/step - loss: 0.6978 - acc: 0.6597 - val_loss: 0.5392 - val_acc: 0.7612\n",
      "Epoch 7/30\n",
      "623/623 [==============================] - 0s 322us/step - loss: 0.5752 - acc: 0.7095 - val_loss: 0.6794 - val_acc: 0.7052\n",
      "Epoch 8/30\n",
      "623/623 [==============================] - 0s 272us/step - loss: 0.5850 - acc: 0.7047 - val_loss: 0.5777 - val_acc: 0.7239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bea99ef98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)#Stop optimization \n",
    "                                                    #when the validation loss hasn't improved for 2 epochs \n",
    "                                                    #by specifying the patience parameter of EarlyStopping() to be 2\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors,target,epochs=30,validation_split=0.3,callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10 that we've used so far. Here, it seems like the optimization stopped after 7 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with wider networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,\n",
    "\n",
    "A model called model_1 is defined which is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "We'll create a new model called model_2 which is similar to model_1, except it has 100 units in each hidden layer.\n",
    "\n",
    "After we create model_2, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument (verbose=False) in the fitting commands to print out fewer updates, since we will look at these graphically instead of as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the new model: model_1\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_1.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niShhiIhIIv8PqhjPus4tT6QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25bf08f8e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Layers to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the new model: model_1\n",
    "model_1 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_1.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "# Add the output layer\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25bf247ea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 =Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will Now use the MNIST Data to work on digit recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...    0.608  0.609  \\\n",
      "0     4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1     3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "2     0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "3     2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "4     8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "5     8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "6     1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "7     2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "8     6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "9     9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "10    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "11    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "12    7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "13    9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "14    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "15    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "16    2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "17    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "18    6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "19    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "20    0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "21    4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "22    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "23    3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "24    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "25    2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "26    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "27    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "28    0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "29    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "...  .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...    ...   \n",
      "1970  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1971  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1972  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1973  3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1974  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1975  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1976  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1977  5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1978  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1979  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1980  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1981  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1982  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1983  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1984  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1985  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1986  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1987  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1988  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1989  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1990  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1991  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1992  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1993  0  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1994  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1995  2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1996  2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1997  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1998  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "1999  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
      "\n",
      "      0.610  0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
      "0         0      0      0      0      0      0      0      0  \n",
      "1         0      0      0      0      0      0      0      0  \n",
      "2         0      0      0      0      0      0      0      0  \n",
      "3         0      0      0      0      0      0      0      0  \n",
      "4         0      0      0      0      0      0      0      0  \n",
      "5         0      0      0      0      0      0      0      0  \n",
      "6         0      0      0      0      0      0      0      0  \n",
      "7         0      0      0      0      0      0      0      0  \n",
      "8         0      0      0      0      0      0      0      0  \n",
      "9         0      0      0      0      0      0      0      0  \n",
      "10        0      0      0      0      0      0      0      0  \n",
      "11        0      0      0      0      0      0      0      0  \n",
      "12        0      0      0      0      0      0      0      0  \n",
      "13        0      0      0      0      0      0      0      0  \n",
      "14        0      0      0      0      0      0      0      0  \n",
      "15        0      0      0      0      0      0      0      0  \n",
      "16        0      0      0      0      0      0      0      0  \n",
      "17        0      0      0      0      0      0      0      0  \n",
      "18        0      0      0      0      0      0      0      0  \n",
      "19        0      0      0      0      0      0      0      0  \n",
      "20        0      0      0      0      0      0      0      0  \n",
      "21        0      0      0      0      0      0      0      0  \n",
      "22        0      0      0      0      0      0      0      0  \n",
      "23        0      0      0      0      0      0      0      0  \n",
      "24        0      0      0      0      0      0      0      0  \n",
      "25        0      0      0      0      0      0      0      0  \n",
      "26        0      0      0      0      0      0      0      0  \n",
      "27        0      0      0      0      0      0      0      0  \n",
      "28        0      0      0      0      0      0      0      0  \n",
      "29        0      0      0      0      0      0      0      0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "1970      0      0      0      0      0      0      0      0  \n",
      "1971      0      0      0      0      0      0      0      0  \n",
      "1972      0      0      0      0      0      0      0      0  \n",
      "1973      0      0      0      0      0      0      0      0  \n",
      "1974      0      0      0      0      0      0      0      0  \n",
      "1975      0      0      0      0      0      0      0      0  \n",
      "1976      0      0      0      0      0      0      0      0  \n",
      "1977      0      0      0      0      0      0      0      0  \n",
      "1978      0      0      0      0      0      0      0      0  \n",
      "1979      0      0      0      0      0      0      0      0  \n",
      "1980      0      0      0      0      0      0      0      0  \n",
      "1981      0      0      0      0      0      0      0      0  \n",
      "1982      0      0      0      0      0      0      0      0  \n",
      "1983      0      0      0      0      0      0      0      0  \n",
      "1984      0      0      0      0      0      0      0      0  \n",
      "1985      0      0      0      0      0      0      0      0  \n",
      "1986      0      0      0      0      0      0      0      0  \n",
      "1987      0      0      0      0      0      0      0      0  \n",
      "1988      0      0      0      0      0      0      0      0  \n",
      "1989      0      0      0      0      0      0      0      0  \n",
      "1990      0      0      0      0      0      0      0      0  \n",
      "1991      0      0      0      0      0      0      0      0  \n",
      "1992      0      0      0      0      0      0      0      0  \n",
      "1993      0      0      0      0      0      0      0      0  \n",
      "1994      0      0      0      0      0      0      0      0  \n",
      "1995      0      0      0      0      0      0      0      0  \n",
      "1996      0      0      0      0      0      0      0      0  \n",
      "1997      0      0      0      0      0      0      0      0  \n",
      "1998      0      0      0      0      0      0      0      0  \n",
      "1999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[2000 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('mnist.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 784)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "predictor=data.drop(['5'],axis=1).as_matrix()\n",
    "n_cols = predictor.shape[1]\n",
    "print(predictor.shape)\n",
    "target =to_categorical(data['5'])\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "1400/1400 [==============================] - 4s 3ms/step - loss: 10.9928 - acc: 0.2943 - val_loss: 10.9036 - val_acc: 0.3100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bf2618f28>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation='relu', input_shape = (784,)))\n",
    "\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictor,target,validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
